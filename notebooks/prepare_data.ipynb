{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Sources\n",
    "\n",
    "This notebook utilizes the following data sources:\n",
    "\n",
    "1. **Worldscope Fundamentals**  \n",
    "   Source: [LSEG - Worldscope Fundamentals](https://www.lseg.com/en/data-analytics/financial-data/company-data/fundamentals-data/worldscope-fundamentals)  \n",
    "   Files should be named:  \n",
    "     - `worldscope_a.csv`  \n",
    "     - `worldscope_b.csv`  \n",
    "   > _Note: The Worldscope dataset is divided into two subsets. The letter \"a\" in the column name denotes the main part of the dataset, containing company fundamentals as originally filed. The letter \"b\" denotes restatements. In case of restatements, we use the most recently avilable data following the logic specified in the code below._\n",
    "\n",
    "2. **Refinitiv ESG Data**  \n",
    "   Source: [LSEG - Refinitiv ESG Scores](https://www.lseg.com/en/data-analytics/sustainable-finance/esg-scores)  \n",
    "   Files should be named:  \n",
    "     - `refinitiv_esg.csv`\n",
    "\n",
    "3. **MSCI ESG Ratings**  \n",
    "   Source: [MSCI ESG Ratings](https://www.msci.com/data-and-analytics/sustainability-solutions/esg-ratings)  \n",
    "   Files should be named:  \n",
    "     - `ESG Ratings Timeseries Expanded {i}.csv`  \n",
    "       _(where `{i}` corresponds to the year of the dataset)_\n",
    "   > _Note: The MSCI dataset is split into several datasets, each containing rating data for a specific year. We concatenate the datasets following the logic specified in the code below._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create Company-Level Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load companies and indices from SRN API\n",
    "# This is our sample\n",
    "companies = pd.read_json(\"https://api.sustainabilityreportingnavigator.com/api/companies\")\n",
    "indices = pd.read_json(\"https://api.sustainabilityreportingnavigator.com/api/indices\")\n",
    "\n",
    "companies['EuroStoxx600'] = ['1cc738c1-e6b1-4f2b-8bec-2d963118de59' in x for x in companies['indices']]\n",
    "companies_se600 = companies[companies['EuroStoxx600'] == True]\n",
    "companies_se600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create company data frame\n",
    "firm_data = companies_se600[['id', 'name', 'isin', 'country', 'sector']]\n",
    "\n",
    "# Create rump times series data frame\n",
    "years = list(range(2014, 2024))\n",
    "firm_data = firm_data.loc[firm_data.index.repeat(len(years))]\n",
    "firm_data['year'] = years * (len(firm_data) // len(years))\n",
    "firm_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "firm_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Merge with Worldscope Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define relevant Worldscope variables\n",
    "ws_vars =  {\n",
    "    # Identifiying\n",
    "    'ITEM6008': 'isin',\n",
    "    'year_':    'year',\n",
    "    'ITEM6011': 'industry_group',\n",
    "    'ITEM5601': 'worldscope_ticker',\n",
    "    'ITEM6105': 'worldscope_permno',\n",
    "    # P&L\n",
    "    'ITEM1001': 'sales',\n",
    "    'ITEM7240': 'salesUSD',\n",
    "    'ITEM1148': 'deprec',\n",
    "    'ITEM1151': 'deprec_amort',\n",
    "    'ITEM18274':'impairment_ppe',\n",
    "    'ITEM18225':'impairment_gw',\n",
    "    'ITEM1250': 'opinc',\n",
    "    'ITEM1751': 'netinc',\n",
    "    'ITEM7250': 'netincUSD',\n",
    "    # B/S\n",
    "    'ITEM2300': 'assets_asreported',\n",
    "    'ITEM2999': 'assets',\n",
    "    'ITEM2301': 'ppe_gross',\n",
    "    'ITEM2401': 'deprec_accum',\n",
    "    'ITEM2501': 'ppe_net',\n",
    "    'ITEM7230': 'assetsUSD',\n",
    "    'ITEM3255': 'debt', \n",
    "    'ITEM3260': 'risk_provisions', \n",
    "    'ITEM1302': 'op_provisions',\n",
    "    'ITEM7210': 'mkcapUSD',\n",
    "    'ITEM7220': 'equityUSD',\n",
    "}\n",
    "\n",
    "keep_cols = list(ws_vars.keys()) + ['freq']   # Need freq for restatements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load and clean Worldscope data (retrieved in April 2025 for universe)\n",
    "# A and B files denote original and restated data\n",
    "ws_raw = (\n",
    "    pd.concat([\n",
    "        pd.read_csv(r'..\\data\\raw\\datasets\\worldscope_a.csv',\n",
    "                    usecols=lambda c: c in keep_cols),\n",
    "        pd.read_csv(r'..\\data\\raw\\datasets\\worldscope_b.csv',\n",
    "                    usecols=lambda c: c in keep_cols)\n",
    "    ], ignore_index=True)\n",
    "    .sort_values(['ITEM6008', 'year_', 'freq'], ascending=[True, True, False])\n",
    ")\n",
    "\n",
    "# Keep the *latest* restatement and fill remaining gaps\n",
    "first_in_group = ws_raw.groupby(['ITEM6008', 'year_']).cumcount() == 0\n",
    "ws_filled      = (\n",
    "    ws_raw.groupby(['ITEM6008', 'year_'])\n",
    "          .transform('ffill')\n",
    "          .fillna(ws_raw.groupby(['ITEM6008', 'year_']).transform('bfill'))\n",
    ")\n",
    "ws_clean = (ws_raw.loc[first_in_group]\n",
    "                     .fillna(ws_filled)\n",
    "                     .reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Rename and keep only relevant columns\n",
    "ws_clean = ws_clean.rename(columns=ws_vars)[ws_vars.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Build a lagged marketcapUSD variable\n",
    "ws_lagged = (\n",
    "    ws_clean[['isin', 'year', 'mkcapUSD']]\n",
    "      .assign(year = lambda d: d['year'] + 1,\n",
    "              mkcapUSD_lagged = lambda d: d.pop('mkcapUSD'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Merge with firm data\n",
    "firm_data = (\n",
    "    firm_data\n",
    "    .merge(ws_clean,  on=['isin', 'year'], how='left')   # current year vars\n",
    "    .merge(ws_lagged, on=['isin', 'year'], how='left')   # lagged mkcap\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Merge with Refinitiv Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from Refinitiv\n",
    "ref = pd.read_csv(r'..\\data\\raw\\datasets\\refinitiv_esg.csv')\n",
    "ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define relevant Refinitiv variables\n",
    "ref_vars = {\n",
    "    'ESGScore': 'ref_esg_score',\n",
    "    'ESGCombinedScore': 'ref_esg_combined_score',\n",
    "    'ESGCControversiesScore': 'ref_esg_controversies_score',\n",
    "    'EnvironmentPillarScore': 'ref_env_score',\n",
    "    'SocialPillarScore': 'ref_soc_score',\n",
    "    'GovernancePillarScore': 'ref_gov_score',\n",
    "    'ESGResourceUseScore': 'ref_res_use_score',\n",
    "    'ESGEmissionsScore': 'ref_emissions_score',\n",
    "    'ESGInnovationScore': 'ref_innovation_score',\n",
    "    'ESGWorkforceScore': 'ref_workforce_score',\n",
    "    'ESGHumanRightsScore': 'ref_human_rights_score',\n",
    "    'ESGCommunityScore': 'ref_community_score',\n",
    "    'ESGProductResponsibilityScore': 'ref_product_responsibility_score',\n",
    "    'ESGManagementScore': 'ref_management_score',\n",
    "    'ESGShareholdersScore': 'ref_shareholders_score',\n",
    "    'ESGCsrStrategyScore': 'ref_csr_strategy_score',\n",
    "    'CO2EquivalentsEmissionDirectScope1': 'ref_scope1',\n",
    "    'CO2EquivalentsEmissionIndirectScope2': 'ref_scope2',\n",
    "    'CO2EquivalentsEmissionIndirectScope3': 'ref_scope3',\n",
    "    'CO2EquivalentsEmissionTotal': 'ref_total',\n",
    "    'ClimateChangeCommercialRisksOpportunities': 'climate_commercial_riskopp_aware',\n",
    "    'CarbonOffsetsCredits': 'carbon_offsets',\n",
    "    'EmissionReductionTargetPercentage': 'emission_reduction_target',\n",
    "    'EmissionReductionTargetYear': 'emission_reduction_target_year',\n",
    "    'EmissionsTrading': 'emission_trading',\n",
    "    'CsrSustainabilityCommittee': 'csr_sust_committee',\n",
    "    'CsrSustainabilityExternalAudit': 'csr_assurance',\n",
    "    'CsrSustainabilityExternalAuditorName': 'csr_assurance_name',\n",
    "    'CsrSustainabilityReportGlobalActivities': 'csr_global_scope',\n",
    "    'CsrSustainabilityReporting': 'csr_separate_report',\n",
    "    'ESGReportingScope': 'esg_reporting_scope',\n",
    "    'GlobalCompactSignatory': 'global_compact_signatory',\n",
    "    'GriReportGuidelines': 'gri_reporting',\n",
    "    'IntegratedStrategyInMdAndA': 'integrated_mda',\n",
    "    'SustainabilityCompensationIncentives': 'esg_compensation', \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to merge firm data with Refinitiv data\n",
    "def merge_with_ref(firm_data, ref, ref_vars):\n",
    "\n",
    "    # Reshape df\n",
    "    ref_pivot = ref.pivot(index=['isin', 'year'], columns='fieldname', values='value').reset_index()\n",
    "\n",
    "    # Rename columns\n",
    "    ref_pivot = ref_pivot.rename(columns=ref_vars)\n",
    "    ref_pivot = ref_pivot.loc[:, ['isin', 'year'] + list(ref_vars.values())]\n",
    "\n",
    "    # Merge\n",
    "    firm_data = pd.merge(firm_data, ref_pivot, on=['isin', 'year'], how='left')\n",
    "\n",
    "    # Prepare lagged data\n",
    "    ref_lagged = ref_pivot[['isin', 'year', 'ref_esg_score', 'ref_esg_controversies_score']].copy()\n",
    "    ref_lagged['year'] += 1\n",
    "\n",
    "    # Rename lagged columns\n",
    "    ref_lagged = ref_lagged.rename(columns={\n",
    "        'ref_esg_score': 'ref_esg_score_lagged',\n",
    "        'ref_esg_controversies_score': 'ref_esg_controversies_score_lagged'\n",
    "    })\n",
    "\n",
    "    # Merge lagged data\n",
    "    firm_data = pd.merge(firm_data, ref_lagged, on=['isin', 'year'], how='left')\n",
    "\n",
    "    return firm_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firm_data = merge_with_ref(firm_data, ref, ref_vars)\n",
    "firm_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Merge with MSCI Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "dir = r'..\\data\\raw\\datasets\\msci'\n",
    "start = 2007\n",
    "end = 2023\n",
    "vars = {\n",
    "    'ISSUER_NAME': 'name',\n",
    "    'ISSUER_ISIN': 'isin',\n",
    "    'AS_OF_DATE': 'msci_as_of_date',\n",
    "    'IVA_INDUSTRY': 'msci_industry',\n",
    "    'IVA_RATING_DATE': 'msci_rating_date',\n",
    "    'IVA_COMPANY_RATING': 'msci_company_rating',\n",
    "    'ENVIRONMENTAL_PILLAR_SCORE': 'msci_env_score',\n",
    "    'SOCIAL_PILLAR_SCORE': 'msci_soc_score',\n",
    "    'GOVERNANCE_PILLAR_SCORE': 'msci_gov_score'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load MSCI data\n",
    "# MSCI data is provided in multiple CSV files, one for each year, with the exception of 2007-2012, which are combined in a single file\n",
    "def load_msci_data(dir, start, end, vars):\n",
    "\n",
    "    data_frames = []\n",
    "\n",
    "    for i in range(start, end):\n",
    "        if i in range(2007, 2013) and i != start:\n",
    "            continue\n",
    "\n",
    "        file_name = (\n",
    "            'ESG Ratings Timeseries Expanded 2007 to 2012.csv'\n",
    "            if i in range(2007, 2013)\n",
    "            else f'ESG Ratings Timeseries Expanded {i}.csv'\n",
    "        )\n",
    "    \n",
    "        read = pd.read_csv(os.path.join(dir, file_name), usecols=list(vars.keys()), sep=';').rename(columns=vars)\n",
    "        data_frames.append(read)\n",
    "\n",
    "    msci = pd.concat(data_frames, ignore_index=True)\n",
    "\n",
    "    # Build yearly data and use the last rating of the year\n",
    "    msci['msci_as_of_date'] = pd.to_datetime(msci['msci_as_of_date'], format='%Y%m%d')\n",
    "    msci['year'] = msci['msci_as_of_date'].dt.year\n",
    "    msci = msci.sort_values(by=['isin', 'msci_as_of_date'], ascending=[True, True])\n",
    "    msci = msci.groupby(['isin', 'year']).last().reset_index()\n",
    "\n",
    "    return msci\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msci = load_msci_data(dir, start, end, vars)\n",
    "msci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lagged MSCI data\n",
    "# Copy the MSCI data\n",
    "msci_lagged = msci.copy()\n",
    "\n",
    "# Create lagged year\n",
    "msci_lagged['lagged_year'] = msci_lagged['year'] + 1  # This will match the firm_data year\n",
    "\n",
    "# Rename columns\n",
    "msci_lagged = msci_lagged.rename(columns={\n",
    "    'msci_as_of_date': 'msci_as_of_date_lagged',\n",
    "    'msci_rating_date': 'msci_rating_date_lagged',\n",
    "    'msci_company_rating': 'msci_company_rating_lagged',\n",
    "    'msci_env_score': 'msci_env_score_lagged',\n",
    "    'msci_soc_score': 'msci_soc_score_lagged',\n",
    "    'msci_gov_score': 'msci_gov_score_lagged'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to merge firm data with MSCI data\n",
    "def merge_with_msci(firm_data, msci):\n",
    "    msci = msci.drop(columns=['name'])\n",
    "    firm_data = pd.merge(firm_data, msci, on=['isin', 'year'], how='left')\n",
    "\n",
    "    # Merge with lagged MSCI data\n",
    "    firm_data = pd.merge(\n",
    "        firm_data,\n",
    "        msci_lagged[\n",
    "            [\n",
    "                'isin',\n",
    "                'lagged_year',\n",
    "                'msci_as_of_date_lagged',\n",
    "                'msci_rating_date_lagged',\n",
    "                'msci_company_rating_lagged',\n",
    "                'msci_env_score_lagged',\n",
    "                'msci_soc_score_lagged',\n",
    "                'msci_gov_score_lagged'\n",
    "            ]\n",
    "        ],\n",
    "        left_on=['isin', 'year'],\n",
    "        right_on=['isin', 'lagged_year'],\n",
    "        how='left'\n",
    "    ).drop(columns=['lagged_year'])\n",
    "    \n",
    "    return firm_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firm_data = merge_with_msci(firm_data, msci)\n",
    "firm_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Save File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firm_data.to_csv(r'..\\data\\raw\\datasets\\firm_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
