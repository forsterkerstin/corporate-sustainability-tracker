{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Postprocess Units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import yaml\n",
    "\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from pint import UnitRegistry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Specify Data Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root = Path.cwd().parents[0]\n",
    "with open(project_root / \"configs\" / \"config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = project_root / config[\"results_dir\"]\n",
    "\n",
    "# Get all subdirectories with valid timestamp names\n",
    "subdirs = [d for d in results_dir.iterdir() if d.is_dir() and \"_\" in d.name]\n",
    "\n",
    "# Get the latest results subdirectory\n",
    "latest_subdir = max(subdirs, key=lambda d: d.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_results_file = latest_subdir / \"numerical_results.csv\"\n",
    "postprocessed_results_file = latest_subdir / \"postprocessed_results.csv\"\n",
    "\n",
    "unit_registry_file = project_root / \"configs\" / \"default_en.txt\"\n",
    "currency_mapping_file = project_root / config[\"datasets_dir\"] / \"fed_rates_yearly.csv\"\n",
    "indicator_metadata_file = project_root / config[\"datasets_dir\"] / \"indicator_metadata.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Add tCO2e, Currencies and Special Units to Pint Unit Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ureg = UnitRegistry(unit_registry_file, case_sensitive=False)\n",
    "\n",
    "# Ensure \"ton\" is correctly mapped to \"tonne\" (metric ton)\n",
    "ureg.define(\"ton = tonne\")\n",
    "ureg.define(\"kt = ton * 1e3\")\n",
    "ureg.define(\"metric_ton = 1e3 * kilogram = t = tonne = metricton\")\n",
    "\n",
    "# Define CO2e emissions units as mass\n",
    "ureg.define(\"gCO2e = [mass]\")\n",
    "ureg.define(\"kgCO2e = 1e3 * gCO2e\")\n",
    "ureg.define(\"tCO2e = 1e3 * kgCO2e\")\n",
    "ureg.define(\"ktCO2e = 1e3 * tCO2e\")\n",
    "ureg.define(\"MtCO2e = 1e3 * ktCO2e\")\n",
    "ureg.define(\"GtCO2e = 1e3 * MtCO2e\")\n",
    "\n",
    "# Define currencies\n",
    "ureg.define(\"USD = [currency] = $ = usd\")\n",
    "\n",
    "# Define base energy per monetary unit\n",
    "ureg.define(\"Wh_per_USD = watt_hour / USD\")\n",
    "ureg.define(\"kWh_per_USD = 1e3 * Wh_per_USD\") \n",
    "ureg.define(\"MWh_per_USD = 1e6 * Wh_per_USD\")\n",
    "\n",
    "# Define joules per USD and related units\n",
    "ureg.define(\"joule_per_USD = joule / USD = 3600 * Wh_per_USD = J_per_USD\")\n",
    "ureg.define(\"kJ_per_USD = 1e3 * J_per_USD\")\n",
    "ureg.define(\"MJ_per_USD = 1e6 * J_per_USD\")\n",
    "ureg.define(\"GJ_per_USD = 1e9 * J_per_USD\")\n",
    "\n",
    "# Define energy per monetary unit\n",
    "ureg.define(\"TJ = 1e12 * joule\")\n",
    "ureg.define(\"MWh = 1e6 * watt_hour\")\n",
    "#ureg.define(\"Wh_per_USD = watt_hour / USD\")\n",
    "#ureg.define(\"joule_per_USD = joule / USD = 3600 * Wh_per_USD = J_per_USD\")\n",
    "\n",
    "# Define emissions per monetary unit\n",
    "ureg.define(\"kgCO2e_per_USD = kgCO2e / USD\")\n",
    "ureg.define(\"tCO2e_per_USD = tCO2e / USD = 1e3 * kgCO2e_per_USD\")\n",
    "ureg.define(\"ktCO2e_per_USD = ktCO2e / USD = 1e3 * tCO2e_per_USD\")\n",
    "ureg.define(\"MtCO2e_per_USD = MtCO2e / USD = 1e3 * ktCO2e_per_USD\")\n",
    "ureg.define(\"GtCO2e_per_USD = GtCO2e / USD = 1e3 * MtCO2e_per_USD\")\n",
    "\n",
    "# Define volume consumed per monetary unit\n",
    "ureg.define(\"cubic_meter = meter ** 3 = m³ = m3\")\n",
    "ureg.define(\"cubic_meter_per_USD = cubic_meter / USD\")\n",
    "\n",
    "# Define area\n",
    "ureg.define(\"square_meter = meter ** 2 = m² = m2\")\n",
    "ureg.define(\"are = 100 * square_meter\")\n",
    "ureg.define(\"square_kilometer = kilometer ** 2 = 1e6 * square_meter = km² = km2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load Dataframe, Set Fixed Type Units, Remove Spaces and Split Fractions by \"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_exclude = [\n",
    "    'srn_compliance_item_id',\n",
    "    'retrieved_context',\n",
    "    'source_documents',\n",
    "    'page_numbers',\n",
    "    'retrieval_time',\n",
    "    'extraction_time',\n",
    "    'num_tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(raw_results_file, usecols=lambda col: col not in columns_to_exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set integers, decimals to NaN and handle percent\n",
    "df_types = pd.read_csv(indicator_metadata_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units_to_drop_list = [\"integer\", \"decimal\", \"date\"]\n",
    "float_list = [\"integer\", \"decimal\", \"percent\"]\n",
    "not_dimensionless_list = [\n",
    "    'years',\n",
    "    'USD',\n",
    "    'tCO2e',\n",
    "    'MWh',\n",
    "    'energy consumed per monetary unit (USD)',\n",
    "    'CO2 equivalent emissions per monetary unit (USD)',\n",
    "    'USD (with indication of whether the amount is increased (+) or decreased (-))',\n",
    "    'tonnes',\n",
    "    'm3',\n",
    "    'volume consumed per monetary unit (USD)',\n",
    "    'hectares',\n",
    "    'hours'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_date(date):\n",
    "    try:\n",
    "        date_str = str(date)\n",
    "        datetime.strptime(date_str, \"%Y-%m-%d\")\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "    \n",
    "def update_date_row(row):\n",
    "    if not is_valid_date(row[\"value\"]):\n",
    "        row[\"model_output_valid\"] = False\n",
    "        row[\"value\"] = None\n",
    "    return row\n",
    "\n",
    "def transform_to_float(row):\n",
    "    try:\n",
    "        # Attempt to convert to float\n",
    "        row[\"value\"] = float(row[\"value\"])\n",
    "    except (ValueError, TypeError):\n",
    "        # If conversion fails, set value to NaN and mark as invalid\n",
    "        row[\"value\"] = np.nan\n",
    "        row[\"model_output_valid\"] = False\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create a mapping from `id` to `type_standard` for faster lookups\n",
    "id_to_type = df_types.set_index(\"id\")[\"type_standard\"]\n",
    "\n",
    "# Step 2: Map `data_point_id` to their corresponding `type_standard` in the main DataFrame\n",
    "df[\"type_standard\"] = df[\"data_point_id\"].map(id_to_type)\n",
    "\n",
    "# Step 3: Handle rows where `type_standard` is in `units_to_drop_list`\n",
    "df.loc[df[\"type_standard\"].isin(units_to_drop_list), \"unit\"] = None\n",
    "\n",
    "# Step 4 Handle rows which should have a unit but don't have one\n",
    "df.loc[df[\"type_standard\"].isin(not_dimensionless_list) & (df[\"value\"].notna()) & (df[\"unit\"].isna()), [\"value\", \"model_output_valid\"]] = None, False\n",
    "\n",
    "# Step 5: Convert to float, otherwise set value to NaN and valid to False\n",
    "float_mask = df[\"type_standard\"].isin(float_list)\n",
    "df.loc[float_mask] = df.loc[float_mask].apply(transform_to_float, axis=1)\n",
    "\n",
    "# Step 6: Handle rows where `type_standard` is \"percent\"\n",
    "percent_mask = df[\"type_standard\"] == \"percent\"\n",
    "df.loc[percent_mask & (df[\"unit\"].isna()), \"value\"] *= 100\n",
    "df.loc[percent_mask & (df[\"unit\"].isna() | df[\"unit\"].str.lower().isin([\"%\", \"percent\", \"per cent\"])), \"unit\"] = \"percent\"\n",
    "df.loc[percent_mask, \"value\"] = df.loc[percent_mask, \"value\"].astype(str)\n",
    "\n",
    "# Step 7: Handle rows where `type_standard` is date\n",
    "date_mask = df[\"type_standard\"] == \"date\"\n",
    "df.loc[date_mask] = df.loc[date_mask].apply(update_date_row, axis=1)\n",
    "\n",
    "# Step 8: Handle rows where \"value\" is None but unit is not None\n",
    "df.loc[df[\"value\"].isnull(), \"unit\"] = None\n",
    "\n",
    "# Step 9: remove dimensionless rows from further processing\n",
    "dimensionless_mask = df.loc[df[\"type_standard\"].isin(units_to_drop_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensionless_mask[\"value_final\"] = dimensionless_mask[\"value\"]\n",
    "dimensionless_mask[\"unit_final\"] = dimensionless_mask[\"unit\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set aside dimensionless and model output False for later concatenation\n",
    "df = df.loc[~df[\"type_standard\"].isin(units_to_drop_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove spaces and split into numerator and denominator\n",
    "df[\"unit_preprocessed\"] = df[\"unit\"].str.replace(r'\\s+', '', regex=True).str.split(\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract numerator and denominator\n",
    "df['numerator'] = df['unit_preprocessed'].apply(lambda x: x[0] if isinstance(x, list) and len(x) > 0 else None)\n",
    "df['denominator'] = df['unit_preprocessed'].apply(lambda x: x[1] if isinstance(x, list) and len(x) > 1 else None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Identify Multipliers with Regex\n",
    "\n",
    "(\"billion\", \"million\", etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_multiplier_and_unit(unit):\n",
    "    multiplier_map = {\n",
    "        'hundredsof': 1e2,\n",
    "        'hundreds': 1e2,\n",
    "        'hundred': 1e2,\n",
    "        'thousandsof': 1e3,\n",
    "        'thousands': 1e3,\n",
    "        'thousand': 1e3,\n",
    "        'millionsof': 1e6,\n",
    "        'millions': 1e6,\n",
    "        'million': 1e6,\n",
    "        'billionsof': 1e9,\n",
    "        'billions': 1e9,\n",
    "        'billion': 1e9,\n",
    "        'trillionsof': 1e12,\n",
    "        'trillions': 1e12,\n",
    "        'trillion': 1e12,\n",
    "    }\n",
    "\n",
    "    # Ensure unit is a str before processing\n",
    "    if not isinstance(unit, str):\n",
    "        return (1, unit)\n",
    "\n",
    "\n",
    "    multiplier = 1  # Default multiplier\n",
    "    base_unit = unit  # Default base unit\n",
    "\n",
    "    unit_lower = unit.lower()\n",
    "\n",
    "    for word, value in multiplier_map.items():\n",
    "        if word in unit_lower:\n",
    "            multiplier = value\n",
    "            base_unit = re.sub(word, '', unit, flags=re.IGNORECASE).strip()\n",
    "            return (multiplier, base_unit)\n",
    "\n",
    "    return (1, unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify multipliers for numerator\n",
    "df['processed_numerator'] = df['numerator'].apply(extract_multiplier_and_unit)\n",
    "df['multiplier_numerator'] = df['processed_numerator'].apply(lambda x: x[0])\n",
    "df['unit_numerator'] = df['processed_numerator'].apply(lambda x: x[1])\n",
    "\n",
    "# Identify multipliers for denominator\n",
    "df['processed_denominator'] = df['denominator'].apply(extract_multiplier_and_unit)\n",
    "df['multiplier_denominator'] = df['processed_denominator'].apply(lambda x: x[0])\n",
    "df['unit_denominator'] = df['processed_denominator'].apply(lambda x: x[1])\n",
    "\n",
    "df.drop(columns=['processed_numerator', 'processed_denominator'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Unify Strings (including suffix-multipliers for currencies)\n",
    "\n",
    "(\"tonnes of CO2 equivalents\", \"€m\", \"eurM\" etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unify_units(unit):\n",
    "    if not isinstance(unit, str):\n",
    "        return unit, 1\n",
    "    \n",
    "    ton_patterns = [\n",
    "        r'\\b(?:metric\\s?)?tons?\\s?(?:of\\s?)?CO(?:2|²|₂)(?:e(?:q(?:uivalent)?)?s?)?\\.?\\b',\n",
    "        r'\\b(?:metric\\s?)?tonnes?\\s?(?:of\\s?)?CO(?:2|²|₂)(?:e(?:q(?:uivalent)?)?s?)?\\.?\\b',\n",
    "        r'\\b(?:metric\\s?)?tons?CO(?:2|²|₂)(?:e(?:q(?:uivalent)?)?s?)?\\.?\\b',\n",
    "        r'\\btonnes?\\s?CO(?:2|²|₂)(?:e(?:q(?:uivalent)?)?s?)?\\.?\\b',\n",
    "        r'\\bmetric\\s?tons?\\s?of\\s?CO(?:2|²|₂)(?:e(?:q(?:uivalent)?)?s?)?\\.?\\b',\n",
    "        r'\\btonnesCO(?:2|²|₂)(?:e(?:q(?:uivalent)?)?s?)?\\.?\\b',\n",
    "        r'\\btCO(?:2|²|₂)(?:e(?:q(?:uivalent)?)?s?)?\\.?\\b',\n",
    "    ]\n",
    "\n",
    "    kiloton_patterns = [\n",
    "        r'\\b(?:metric\\s?)?kilotons?\\s?(?:of\\s?)?CO(?:2|²|₂)(?:e(?:q(?:uivalent)?)?s?)?\\.?\\b',\n",
    "        r'\\b(?:metric\\s?)?kilotonnes?\\s?(?:of\\s?)?CO(?:2|²|₂)(?:e(?:q(?:uivalent)?)?s?)?\\.?\\b',\n",
    "        r'\\b(?:metric\\s?)?kilotons?CO(?:2|²|₂)(?:e(?:q(?:uivalent)?)?s?)?\\.?\\b',\n",
    "        r'\\bkilotonnes?\\s?CO(?:2|²|₂)(?:e(?:q(?:uivalent)?)?s?)?\\.?\\b',\n",
    "        r'\\bmetric\\s?kiloton\\s?of\\s?CO(?:2|²|₂)(?:e(?:q(?:uivalent)?)?s?)?\\.?\\b',\n",
    "        r'\\bkilotonnesCO(?:2|²|₂)(?:e(?:q(?:uivalent)?)?s?)?\\.?\\b',\n",
    "        r'\\bktCO(?:2|²|₂)(?:e(?:q(?:uivalent)?)?s?)?\\.?\\b',\n",
    "    ]\n",
    "\n",
    "    megaton_patterns = [\n",
    "        r'\\b(?:metric\\s?)?megatonnes?\\s?(?:of\\s?)?CO(?:2|²|₂)(?:e(?:q(?:uivalent)?)?s?)?\\.?\\b',\n",
    "        r'\\b(?:metric\\s?)?megatons?\\s?(?:of\\s?)?CO(?:2|²|₂)(?:e(?:q(?:uivalent)?)?s?)?\\.?\\b',\n",
    "        r'\\b(?:metric\\s?)?megatons?CO(?:2|²|₂)(?:e(?:q(?:uivalent)?)?s?)?\\.?\\b',\n",
    "        r'\\bmegatonnes?\\s?CO(?:2|²|₂)(?:e(?:q(?:uivalent)?)?s?)?\\.?\\b',\n",
    "        r'\\bmetric\\s?megaton\\s?of\\s?CO(?:2|²|₂)(?:e(?:q(?:uivalent)?)?s?)?\\.?\\b',\n",
    "        r'\\bmegatonnesCO(?:2|²|₂)(?:e(?:q(?:uivalent)?)?s?)?\\.?\\b',\n",
    "        r'\\bMtCO(?:2|²|₂)(?:e(?:q(?:uivalent)?)?s?)?\\.?\\b',\n",
    "    ]\n",
    "\n",
    "    gigaton_patterns = [\n",
    "        r'\\b(?:metric\\s?)?gigatonnes?\\s?(?:of\\s?)?CO(?:2|²|₂)(?:e(?:q(?:uivalent)?)?s?)?\\.?\\b',\n",
    "        r'\\b(?:metric\\s?)?gigatons?\\s?(?:of\\s?)?CO(?:2|²|₂)(?:e(?:q(?:uivalent)?)?s?)?\\.?\\b',\n",
    "        r'\\b(?:metric\\s?)?gigatons?CO(?:2|²|₂)(?:e(?:q(?:uivalent)?)?s?)?\\.?\\b',\n",
    "        r'\\bgigatonnes?\\s?CO(?:2|²|₂)(?:e(?:q(?:uivalent)?)?s?)?\\.?\\b',\n",
    "        r'\\bmetric\\s?gigaton\\s?of\\s?CO(?:2|²|₂)(?:e(?:q(?:uivalent)?)?s?)?\\.?\\b',\n",
    "        r'\\bgigatonnesCO(?:2|²|₂)(?:e(?:q(?:uivalent)?)?s?)?\\.?\\b',\n",
    "        r'\\bGtCO(?:2|²|₂)(?:e(?:q(?:uivalent)?)?s?)?\\.?\\b',\n",
    "    ]\n",
    "\n",
    "    kg_patterns = [\n",
    "        r'\\bkg\\s?(?:of\\s?)?CO(?:2|²|₂)(?:e(?:quivalent)?s?)?\\b',\n",
    "        r'\\bkilograms?\\s?(?:of\\s?)?CO(?:2|²|₂)(?:e(?:quivalent)?s?)?\\b',\n",
    "        r'\\bkilos?\\s?(?:of\\s?)?CO(?:2|²|₂)(?:e(?:quivalent)?s?)?\\b',\n",
    "        r'\\bkilogramsCO(?:2|²|₂)(?:e(?:quivalent)?s?)?\\b',\n",
    "    ]\n",
    "    # Check for matches with metric tons patterns\n",
    "    for pattern in gigaton_patterns:\n",
    "        if re.search(pattern, unit, re.IGNORECASE):\n",
    "            return 'GtCO2e', 1\n",
    "\n",
    "    # Check for matches with metric tons patterns\n",
    "    for pattern in megaton_patterns:\n",
    "        if re.search(pattern, unit, re.IGNORECASE):\n",
    "            return 'MtCO2e', 1\n",
    "\n",
    "    # Check for matches with metric tons patterns\n",
    "    for pattern in kiloton_patterns:\n",
    "        if re.search(pattern, unit, re.IGNORECASE):\n",
    "            return 'ktCO2e', 1\n",
    "    \n",
    "    # Check for matches with metric tons patterns\n",
    "    for pattern in ton_patterns:\n",
    "        if re.search(pattern, unit, re.IGNORECASE):\n",
    "            return 'tCO2e', 1\n",
    "\n",
    "    # Check for matches with kilograms patterns\n",
    "    for pattern in kg_patterns:\n",
    "        if re.search(pattern, unit, re.IGNORECASE):\n",
    "            return 'kgCO2e', 1\n",
    "        \n",
    "    # Check for cubic_meters patterns\n",
    "    if unit.lower() in [\"m3\", \"m³\", \"cubicmeter\", \"cubicmeters\"]:\n",
    "        return 'cubic_meter', 1\n",
    "    \n",
    "    # Check for square_meters patterns\n",
    "    if unit.lower() in [\"m2\", \"m²\", \"squaremeter\", \"squaremeters\"]:\n",
    "        return 'square_meter', 1\n",
    "\n",
    "    multiplier_map = {\n",
    "        'k': 1e3,\n",
    "        'm': 1e6,\n",
    "        'mio': 1e6,\n",
    "        'mio.': 1e6,\n",
    "        'mn': 1e6,\n",
    "        'b': 1e9,\n",
    "        'bn': 1e9,\n",
    "        't': 1e12,\n",
    "        'tn': 1e12\n",
    "    }\n",
    "\n",
    "    currency_pattern = r'^(?!.*\\d)(k|m|mio|mio\\.|mn|b|bn|t|tn)?(EUR|€|USD|\\$|GBP|£|BRL|CAD|CNY|DKK|NOK|SEK|SGD|CHF|PLN)(k|m|mio|mio\\.|mn|b|bn|t|tn)?$'\n",
    "\n",
    "    currency_symbol_map = {\n",
    "        '€': 'EUR',\n",
    "        '$': 'USD',\n",
    "        '£': 'GBP'\n",
    "    }\n",
    "\n",
    "    match = re.search(currency_pattern, unit, re.IGNORECASE)\n",
    "    if match:\n",
    "        # Extract prefix multiplier, currency symbol, and suffix multiplier safely\n",
    "        prefix = match.group(1)\n",
    "        currency_symbol = match.group(2)\n",
    "        suffix = match.group(3)\n",
    "\n",
    "        # Ensure prefix and suffix are valid before calling .lower()\n",
    "        prefix = prefix.lower() if prefix and prefix is not None else \"\"\n",
    "        suffix = suffix.lower() if suffix and suffix is not None else \"\"\n",
    "        \n",
    "        # Map symbol to standard currency code if necessary\n",
    "        currency_symbol = currency_symbol_map.get(currency_symbol, currency_symbol).upper()\n",
    "\n",
    "        # Resolve multipliers (default to 1 if no prefix/suffix)\n",
    "        prefix_multiplier = multiplier_map.get(prefix, 1)\n",
    "        suffix_multiplier = multiplier_map.get(suffix, 1)\n",
    "\n",
    "        # Calculate the combined multiplier\n",
    "        total_multiplier = prefix_multiplier * suffix_multiplier\n",
    "        return currency_symbol, total_multiplier\n",
    "\n",
    "    # Return original unit if no match\n",
    "    return unit, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to extract multipliers and base units\n",
    "df['unit_numerator_unified'] = df['unit_numerator'].apply(lambda x: unify_units(x))\n",
    "df['unit_numerator_regex'] = df['unit_numerator_unified'].apply(lambda x: x[0])\n",
    "df['suffix_multiplier_numerator'] = df['unit_numerator_unified'].apply(lambda x: x[1])\n",
    "\n",
    "df['unit_denominator_unified'] = df['unit_denominator'].apply(lambda x: unify_units(x))\n",
    "df['unit_denominator_regex'] = df['unit_denominator_unified'].apply(lambda x: x[0])\n",
    "df['suffix_multiplier_denominator'] = df['unit_denominator_unified'].apply(lambda x: x[1])\n",
    "\n",
    "df.drop(columns=['unit_numerator_unified', 'unit_denominator_unified'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop Redundant Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\n",
    "    'unit_preprocessed',\n",
    "    'numerator',\n",
    "    'denominator',\n",
    "    'unit_numerator',\n",
    "    'unit_denominator',\n",
    "    ], inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Transform into Pint Quantities and Apply Multipliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert to USD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read currency conversion file\n",
    "df_currency = pd.read_csv(currency_mapping_file, delimiter=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the column to \"year\"\n",
    "df_currency.rename(columns={'Time Period': 'year'}, inplace=True)\n",
    "# Rename other columns to remove \"_USD\"\n",
    "df_currency.rename(columns=lambda col: col.replace('/USD', '') if '/USD' in col else col, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_usd(row):\n",
    "    year = row[\"year\"]\n",
    "    # Check and update numerator\n",
    "    if row['unit_numerator_regex'] in [col for col in df_currency.columns if col != \"year\"]:\n",
    "        row['multiplier_numerator'] *= df_currency[row['unit_numerator_regex']].loc[df_currency[\"year\"] == year].values[0]\n",
    "        row['unit_numerator_regex'] = 'USD'\n",
    "\n",
    "    # Check and update denominator\n",
    "    if row['unit_denominator_regex'] in df_currency.columns:\n",
    "        row['multiplier_denominator'] *= df_currency[row['unit_denominator_regex']].loc[df_currency[\"year\"] == year].values[0]\n",
    "        row['unit_denominator_regex'] = 'USD'\n",
    "\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to the DataFrame\n",
    "df_converted = df.apply(convert_to_usd, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenate numerator and denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the \"unit_regex\" column\n",
    "def combine_units(row):\n",
    "    num = row['unit_numerator_regex']\n",
    "    den = row['unit_denominator_regex']\n",
    "    \n",
    "    if pd.isna(num) and pd.isna(den):\n",
    "        return None\n",
    "    elif pd.isna(num):\n",
    "        return f\"per_{den}\"\n",
    "    elif pd.isna(den):\n",
    "        return num\n",
    "    else:\n",
    "        return f\"{num}_per_{den}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_converted['unit_regex'] = df_converted.apply(combine_units, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_into_pint(unit):\n",
    "    if pd.isna(unit):\n",
    "        return unit\n",
    "    else:\n",
    "        try:\n",
    "            return ureg(unit)\n",
    "        except Exception:\n",
    "            return \"unification_error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform into pint units\n",
    "df_converted['unit_pint'] = df_converted['unit_regex'].apply(transform_into_pint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set unification error units to None and model output to False\n",
    "error_mask = df_converted[\"unit_pint\"] == \"unification_error\"\n",
    "df_converted.loc[error_mask, \"unit_pint\"] = None\n",
    "df_converted.loc[error_mask, \"model_output_valid\"] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Convert Value + Unit Pairs to Standard EFRAG Units\n",
    "\n",
    "- If pint unit: convert with pint\n",
    "- If NOT pint unit: set to NaN and set model_output_valid to False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert Value to Float except for Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mask for rows where standard_type is not 'date'\n",
    "not_date_mask = df_converted['type_standard'] != 'date'\n",
    "\n",
    "# Store original NaN mask for 'value' to distinguish existing NaN values\n",
    "original_nan_mask = df_converted['value'].isna()\n",
    "\n",
    "# Attempt to convert 'value' to float for non-date rows\n",
    "df_converted.loc[not_date_mask, 'value_numeric'] = pd.to_numeric(df_converted.loc[not_date_mask, 'value'], errors='coerce')\n",
    "\n",
    "# Update 'model_output_valid' to False for conversion errors only (exclude original NaNs)\n",
    "conversion_error_mask = df_converted['value_numeric'].isna() & ~original_nan_mask & not_date_mask\n",
    "df_converted.loc[conversion_error_mask, 'model_output_valid'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the calculations only for rows in not_date_mask\n",
    "df_converted.loc[not_date_mask, 'value_final'] = (\n",
    "    df_converted.loc[not_date_mask, 'value_numeric']\n",
    "    * df_converted.loc[not_date_mask, 'multiplier_numerator']\n",
    "    * df_converted.loc[not_date_mask, 'suffix_multiplier_numerator']\n",
    "    / df_converted.loc[not_date_mask, 'multiplier_denominator']\n",
    "    / df_converted.loc[not_date_mask, 'suffix_multiplier_denominator']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop multiplier columns\n",
    "df_converted.drop(columns=['multiplier_numerator', 'suffix_multiplier_numerator', 'multiplier_denominator', 'suffix_multiplier_denominator'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out rows with NaN or \"date\" in the unit_pint column\n",
    "valid_rows = df_converted['unit_pint'].notna() & (df_converted['type_standard'] != 'date')\n",
    "df_filtered = df_converted[valid_rows].copy()  # Filtered DataFrame\n",
    "\n",
    "# Create the column with pint quantities (unit_pint is already a quantity)\n",
    "df_filtered[\"quantity_pint\"] = df_filtered['value_final'] * df_filtered['unit_pint']\n",
    "\n",
    "# Optionally reassign to the original DataFrame (if needed)\n",
    "df_converted.loc[valid_rows, \"quantity_pint\"] = df_filtered[\"quantity_pint\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_unit_dict = {\n",
    "    'date': None,\n",
    "    'years': ureg.year,\n",
    "    'integer': None,\n",
    "    'percent': ureg.percent,\n",
    "    'USD': ureg.USD,\n",
    "    'tCO2e': ureg.tCO2e,\n",
    "    'MWh': ureg.MWh,\n",
    "    'energy consumed per monetary unit (USD)': ureg.MWh_per_USD,\n",
    "    'CO2 equivalent emissions per monetary unit (USD)': ureg.tCO2e_per_USD,\n",
    "    'USD (with indication of whether the amount is increased (+) or decreased (-))': ureg.USD,\n",
    "    'tonnes': ureg.metric_ton,\n",
    "    'm3': ureg.cubic_meter,\n",
    "    'volume consumed per monetary unit (USD)': ureg.cubic_meter_per_USD,\n",
    "    'hectares': ureg.hectares,\n",
    "    'decimal': None,\n",
    "    'hours': ureg.hours,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_target(row):\n",
    "    quantity = row['quantity_pint']\n",
    "    # Skip rows with NaN or \"date\" in the unit column\n",
    "    if pd.isna(quantity) or row['type_standard'] == 'date':\n",
    "        return quantity, row[\"model_output_valid\"]\n",
    "    try:\n",
    "        # Determine target unit\n",
    "        target_unit = type_unit_dict[row['type_standard']]\n",
    "        # Convert to the target unit\n",
    "        converted_quantity = quantity.to(target_unit)\n",
    "        return converted_quantity, True  # Return the numerical value\n",
    "    except Exception as e:\n",
    "        # Handle conversion errors separately\n",
    "        print(f\"Conversion error for row {row.name}: {e}\")\n",
    "        return None, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_converted[['quantity_converted', 'model_output_valid']] = pd.DataFrame(\n",
    "    df_converted.apply(convert_to_target, axis=1).tolist(), index=df_converted.index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to handle extraction\n",
    "def extract_value_and_unit(quantity):\n",
    "    if isinstance(quantity, ureg.Quantity):  # Check if it's a pint.Quantity\n",
    "        return quantity.magnitude, str(quantity.units)\n",
    "    elif isinstance(quantity, str):  # Check if it's a string (e.g., a date)\n",
    "        return quantity, None\n",
    "    elif pd.isna(quantity):  # Handle NaN values\n",
    "        return None, None\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected type in quantity_pint: {type(quantity)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the extraction function and assign to new columns\n",
    "df_converted[['value_final', 'unit_final']] = df_converted['quantity_converted'].apply(extract_value_and_unit).apply(pd.Series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenate dimensionless mask and converted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the two DataFrames\n",
    "df_final = pd.concat([dimensionless_mask, df_converted])\n",
    "\n",
    "# Restore the original order using sort_index\n",
    "df_final = df_final.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Step: Set unit to None for model output valid = False\n",
    "df_final.loc[df_final[\"model_output_valid\"] == False, [\"value_final\", \"unit_final\"]] = None\n",
    "\n",
    "# Replace NaN with None for value\n",
    "df_final[\"value_final\"] = df_final[\"value_final\"].where(pd.notna(df_final[\"value_final\"]), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.drop(columns=[\n",
    "    'value',\n",
    "    'unit',\n",
    "    'unit_numerator_regex',\n",
    "    'unit_denominator_regex',\n",
    "    'unit_regex',\n",
    "    'unit_pint',\n",
    "    'value_numeric',\n",
    "    'quantity_pint',\n",
    "    'quantity_converted'\n",
    "    ], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Save Postprocessed Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv(postprocessed_results_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
